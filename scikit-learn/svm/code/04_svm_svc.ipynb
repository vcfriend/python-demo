{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1810,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# % matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from matplotlib import cm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.style.use(plt.style.available[0])  #可以通过下标进行选择适合自己的画图样式\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.datasets import make_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1812,
   "outputs": [],
   "source": [
    "# 两个信息特性，每个类一个集群\n",
    "X, y = make_classification(n_samples=50,  #(default=100)样本数\n",
    "                           n_features=3,  #(default=20)特征序总数。这些包括随机绘制的n_informative信息特征，n_redundant冗余特征，n_repeated重复特征和n_features-n_informative-n_redundant-n_repeated无用特征。\n",
    "                           n_redundant=0,  #(default=2)冗余特征数量\n",
    "                           n_repeated=0,  #(default=0)从信息性和冗余性特征中随机抽取的重复性特征的数量。\n",
    "                           n_informative=1,  #有效特征个数\n",
    "                           n_clusters_per_class=1,  #(default=2)每个类的簇数\n",
    "                           n_classes=2,  #(default=2)分类问题的类（或标签）数\n",
    "                           flip_y=0.8,  #(default=0.01)类别随机分配的样本比例\n",
    "                           random_state=2,  #确定用于生成数据集的随机数生成。 为多个函数调用传递可重复输出的int值。\n",
    "                           )\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1813,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X=  [[ 0.41819493  0.69619798  0.69741627]\n",
      " [-0.42896232 -0.63467931  0.50839624]\n",
      " [-1.61274204 -1.09873895  1.58448706]]\n",
      "y=  [1 1 1 1 0]\n",
      "(50, 3) 2\n",
      "(50,) 1\n"
     ]
    }
   ],
   "source": [
    "print('X= ', X[:3])\n",
    "print('y= ', y[:5])\n",
    "print(X.shape, X.ndim)\n",
    "print(y.shape, y.ndim)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1814,
   "outputs": [],
   "source": [
    "#将数据划分为训练集和验证集\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1817,
   "outputs": [],
   "source": [
    "# 3. 特征工程（标准化）\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "standardScaler = StandardScaler()\n",
    "\n",
    "# 测试集 计算平均值和标准偏差 缩放特征集\n",
    "X_train = standardScaler.fit_transform(X_train)\n",
    "X_test = standardScaler.transform(X_test)\n",
    "# X = standardScaler.fit_transform(X)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1818,
   "outputs": [],
   "source": [
    "# Fit regression model\n",
    "classifiers = [\n",
    "    SVC(kernel=\"rbf\", C=1,  #浮点数，默认= 1.0 正则化参数。正则化的强度与C成反比。必须严格为正。此惩罚系数是l2惩罚系数的平方\n",
    "        gamma=.5,  #浮点数或者{‘scale’, ‘auto’} , 默认=’scale’ 核系数包含‘rbf’, ‘poly’ 和‘sigmoid’\n",
    "        # 如果gamma='scale'(默认)，则它使用1 / (n_features * X.var())作为gamma的值，如果是auto，则使用1 / n_features。在0.22版本有改动：默认的gamma从“auto”改为“scale”。\n",
    "        probability=True,  #是否启用概率估计。必须在调用fit之前启用此参数，因为该方法内部使用5折交叉验证，因此会减慢该方法的速度\n",
    "        ),\n",
    "    SVC(kernel=\"linear\", C=1, gamma=1, probability=True),\n",
    "    SVC(kernel=\"poly\", C=1, gamma=\"auto\", degree=3, coef0=1),\n",
    "]\n",
    "\n",
    "names = [\n",
    "    \"RBF SVM\",\n",
    "    \"Linear SVM\",\n",
    "    \"poly\"\n",
    "]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1818,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1819,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RBF SVM, svcs=SVC(C=1, gamma=0.5, probability=True)\n",
      "估计器的参数: {'C': 1, 'break_ties': False, 'cache_size': 200, 'class_weight': None, 'coef0': 0.0, 'decision_function_shape': 'ovr', 'degree': 3, 'gamma': 0.5, 'kernel': 'rbf', 'max_iter': -1, 'probability': True, 'random_state': None, 'shrinking': True, 'tol': 0.001, 'verbose': False}\n",
      "训练集R2评分: 0.78 \n",
      "测试集R2评分: 0.92 \n",
      "Linear SVM, svcs=SVC(C=1, gamma=1, kernel='linear', probability=True)\n",
      "估计器的参数: {'C': 1, 'break_ties': False, 'cache_size': 200, 'class_weight': None, 'coef0': 0.0, 'decision_function_shape': 'ovr', 'degree': 3, 'gamma': 1, 'kernel': 'linear', 'max_iter': -1, 'probability': True, 'random_state': None, 'shrinking': True, 'tol': 0.001, 'verbose': False}\n",
      "训练集R2评分: 0.65 \n",
      "测试集R2评分: 0.77 \n",
      "poly, svcs=SVC(C=1, coef0=1, gamma='auto', kernel='poly')\n",
      "估计器的参数: {'C': 1, 'break_ties': False, 'cache_size': 200, 'class_weight': None, 'coef0': 1, 'decision_function_shape': 'ovr', 'degree': 3, 'gamma': 'auto', 'kernel': 'poly', 'max_iter': -1, 'probability': False, 'random_state': None, 'shrinking': True, 'tol': 0.001, 'verbose': False}\n",
      "训练集R2评分: 0.76 \n",
      "测试集R2评分: 0.77 \n"
     ]
    }
   ],
   "source": [
    "for name, clf in zip(names, classifiers):\n",
    "    performance = clf.fit(X_train, y_train.ravel())\n",
    "    # 获取预测值\n",
    "    y_test_pred = performance.predict(X_test)\n",
    "    # 显示估计器\n",
    "    print(f'%s, svcs=%s' % (name, clf))\n",
    "    # 获取这个估计器的参数\n",
    "    print(f'估计器的参数: %s' % (clf.get_params()))\n",
    "    # https://blog.csdn.net/gracejpw/article/details/101546293\n",
    "    # 返回预测的决定系数R^2\n",
    "    # R^2越接近于1，模型的拟合优度越高。\n",
    "    print(f'训练集R2评分: %.2f ' % (clf.score(X_train, y_train)))\n",
    "    print(f'测试集R2评分: %.2f ' % (clf.score(X_test, y_test)))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1819,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1878,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kernel 核函数名称 linear\n",
      "support_ 形如(28,)的数组,支持向量的下标,显示前10个 \n",
      "=[ 5  8  9 11 12 14 16 19 20 21]\n",
      "support_vectors_ 形如(28, 3)的数组,支持向量, 显示前3行 \n",
      "=[[-0.595 -0.527  0.736]\n",
      " [-0.733  1.032  0.289]\n",
      " [-0.634 -0.363  0.254]]\n",
      "n_support_ 形如(2,)的数组,每个类别的支持向量数量, \n",
      "=[14 14]\n",
      "dual_coef_ 形如(1, 28)的数组,决策函数中支持向量的对偶系数, \n",
      "=[[-1. -1. -1. -1. -1.]]\n",
      "coef_ 形如(1, 3)的数组,分配给特征的权重, \n",
      "=[[1.078 0.06  0.237]]，仅在线性内核的情况下可用\n",
      "intercept_ 形如(1,)的数组,添加到决策函数的常量（也称为偏差或截距）, \n",
      "=[0.068]\n",
      "fit_status_ 如果拟合无误，则为0；如果算法未收敛，则为1,fit_status_= 0\n",
      "classes_ 形如(2,)的数组 不重复的类别标签, \n",
      "=[0 1]\n",
      "probA_ 形如(2 * (2-1) / 2,)=(1,)的数组, \n",
      "=[-0.394], 如果 probability=False，则为空数组。\n",
      "probB_ 形如(2 * (2-1) / 2,)=(1,)的数组, \n",
      "=[0.128], 如果 probability=False，则为空数组。\n",
      "class_weight_ 形如(2,)的数组每个类的参数C的乘数。根据 class_weight 参数进行计算。\n",
      "=[1. 1.]\n",
      "shape_fit_ 形如(n_dimensions_of_X,)的整数型元祖 训练向量X的数组维度 (37, 3)\n"
     ]
    }
   ],
   "source": [
    "#设定numpy显示浮点数精度的小数位数\n",
    "np.set_printoptions(precision=3)\n",
    "# 核函数返回参数介绍\n",
    "# clf所使用的分类器\n",
    "clf = classifiers[1]\n",
    "print('kernel 核函数名称', clf.kernel)  #核函数名称\n",
    "print('support_ 形如%s的数组,支持向量的下标,显示前10个 \\n=%s'\n",
    "      % (clf.support_.shape, clf.support_[:10]))  #形如(n_SV,)的数组,支持向量的指标。\n",
    "print('support_vectors_ 形如%s的数组,支持向量, 显示前3行 \\n=%s'\n",
    "      %(clf.support_vectors_.shape, clf.support_vectors_[:3]))  #形如(n_SV, n_features)的数组, 支持向量\n",
    "print('n_support_ 形如%s的数组,每个类别的支持向量数量, \\n=%s'\n",
    "      %(clf.n_support_.shape, clf.n_support_))  #形如(n_class)的数组，每个类别的支持向量数量。\n",
    "print('dual_coef_ 形如%s的数组,决策函数中支持向量的对偶系数, \\n=%s'  #形如(n_class-1, n_SV)的数组, 决策函数中支持向量的对偶系数\n",
    "      %(clf.dual_coef_.shape, clf.dual_coef_[:3,:5]))  #显示前三个类型的前3个系数\n",
    "print(#clf.coef_ 形如(n_class * (n_class-1) / 2, n_features)的数组,分配给特征的权重（原始问题的系数），仅在线性内核的情况下可用。\n",
    "    ('coef_ 形如%s的数组,分配给特征的权重, \\n=%s，仅在线性内核的情况下可用'%(clf.coef_.shape, clf.coef_)) if clf.kernel == 'linear' else 0)\n",
    "print('intercept_ 形如%s的数组,添加到决策函数的常量（也称为偏差或截距）, \\n=%s'%(clf.intercept_.shape,clf.intercept_))  #形如(n_class * (n_class-1) / 2,)的数组,决策函数中的常量。\n",
    "print('fit_status_ 如果拟合无误，则为0；如果算法未收敛，则为1,fit_status_=',clf.fit_status_)  #整数型 如果拟合无误，则为0；如果算法未收敛，则为1\n",
    "print('classes_ 形如%s的数组 不重复的类别标签, \\n=%s'  #二分类情况下就只有2个标签\n",
    "      %(clf.classes_.shape, clf.classes_))  #形如(n_classes,)的数组 不重复类别标签\n",
    "print('probA_ 形如(%s * (%s-1) / 2,)=%s的数组, \\n=%s, 如果 probability=False，则为空数组。'\n",
    "      %(clf.classes_.size,clf.classes_.size,clf.probA_.shape, clf.probA_)\n",
    "      )  #probA_ 形如(n_class * (n_class-1) / 2,)的数组\n",
    "'''如果 probability=True，则它对应于在普拉特缩放中学习的参数，以根据决策值产生概率估计。\n",
    "\n",
    "普拉特定标使用逻辑函数1 /（1 + exp（decision_value * probA_ + probB_）），\n",
    "其中从数据集[2]了解probA_和probB_。有关多类案件和培训程序的更多信息，请参见[1]的第8节。'''\n",
    "print('probB_ 形如(%s * (%s-1) / 2,)=%s的数组, \\n=%s, 如果 probability=False，则为空数组。'\n",
    "      %(clf.classes_.size,clf.classes_.size,clf.probB_.shape, clf.probB_))\n",
    "\n",
    "print('class_weight_ 形如(%s,)的数组每个类的参数C的乘数。根据 class_weight 参数进行计算。\\n=%s'\n",
    "      %(clf.classes_.size, clf.class_weight_)\n",
    "      )  #形如(n_class,)的数组每个类的参数C的乘数。根据class_weight参数进行计算。\n",
    "\n",
    "print('shape_fit_ 形如(n_dimensions_of_X,)的整数型元祖 训练向量X的数组维度', clf.shape_fit_)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1924,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classes_ 类别标签 = [0 1]\n",
      "predict_proba 返回测试样本的各类标签 概率. 每行概率合计为 1 \n",
      " [[0.47  0.53 ]\n",
      " [0.333 0.667]\n",
      " [0.582 0.418]\n",
      " [0.433 0.567]\n",
      " [0.578 0.422]\n",
      " [0.418 0.582]\n",
      " [0.392 0.608]\n",
      " [0.352 0.648]\n",
      " [0.393 0.607]\n",
      " [0.295 0.705]]\n",
      "predict 返回测试样本的所属类别标签\n",
      "predict [0 1 0 1 0 1 1 1 1 1 1 0 1]\n",
      "y_test  [1 1 0 0 1 1 1 1 1 1 1 0 1]\n",
      "测试样本预测类别与测试目标类别不同的由predict_proba计算的概率值\n",
      " [[0.47  0.53 ]\n",
      " [0.433 0.567]\n",
      " [0.578 0.422]]\n",
      "predict 返回训练样本的所属类别标签\n",
      "predict [1 0 0 0 1 0 1 1 0 0 1 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 1 1 0 1 1 0 0 0 0 1]\n",
      "y_train [1 1 1 1 1 0 1 1 0 0 1 0 0 1 0 1 0 1 0 0 0 0 1 1 1 1 1 1 1 0 1 1 0 0 0 0 0]\n",
      "训练样本预测类别与训练目标类别不同的由predict_proba计算的概率值\n",
      " [[0.471 0.529]\n",
      " [0.531 0.469]\n",
      " [0.509 0.491]\n",
      " [0.369 0.631]\n",
      " [0.543 0.457]\n",
      " [0.354 0.646]\n",
      " [0.535 0.465]\n",
      " [0.5   0.5  ]\n",
      " [0.546 0.454]\n",
      " [0.494 0.506]\n",
      " [0.564 0.436]\n",
      " [0.486 0.514]\n",
      " [0.285 0.715]]\n"
     ]
    }
   ],
   "source": [
    "print('classes_ 类别标签 =',clf.classes_)\n",
    "print('predict_proba 返回测试样本的各类标签 概率. 每行概率合计为 1 \\n', clf.predict_proba(X_test)[:10])\n",
    "print('predict 返回测试样本的所属类别标签\\npredict', clf.predict(X_test)[:])\n",
    "print('y_test ',y_test[:])\n",
    "id_test = clf.predict(X_test) != y_test  #测试样本预测类别与测试目标类别不同的下标\n",
    "print('测试样本预测类别与测试目标类别不同的由predict_proba计算的概率值\\n',clf.predict_proba(X_test)[id_test])\n",
    "print('predict 返回训练样本的所属类别标签\\npredict', clf.predict(X_train)[:])\n",
    "print('y_train',y_train[:])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1939,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练样本预测类别与训练目标类别不同的由predict_proba计算的概率值\n",
      " [[0.471 0.529]\n",
      " [0.531 0.469]\n",
      " [0.509 0.491]\n",
      " [0.369 0.631]\n",
      " [0.543 0.457]\n",
      " [0.354 0.646]\n",
      " [0.535 0.465]\n",
      " [0.5   0.5  ]\n",
      " [0.546 0.454]\n",
      " [0.494 0.506]\n",
      " [0.564 0.436]\n",
      " [0.486 0.514]\n",
      " [0.285 0.715]]\n",
      "(13, 2)\n",
      "预测类别不同的区间个数统计[ 3  2 16  2  3]\n",
      "概率统计区间分布[0.285 0.371 0.457 0.543 0.629 0.715]\n",
      "预测类别相同的区间个数统计[ 5 13 12 13  5]\n",
      "概率统计区间分布[0.245 0.347 0.449 0.551 0.653 0.755]\n"
     ]
    }
   ],
   "source": [
    "id_train_no = clf.predict(X_train)[:] != y_train  #训练样本预测类别与训练目标类别不同的下标\n",
    "id_train_ok = clf.predict(X_train)[:] == y_train  #训练样本预测类别与训练目标类别不同的下标\n",
    "print('训练样本预测类别与训练目标类别不同的由predict_proba计算的概率值\\n', clf.predict_proba(X_train)[id_train_no])\n",
    "\n",
    "proba_no = clf.predict_proba(X_train)[id_train_no]  #训练样本预测类别与训练目标类别不同的由predict_proba计算的概率值\n",
    "proba_ok = clf.predict_proba(X_train)[id_train_ok]\n",
    "print(proba_no.shape)\n",
    "\n",
    "# 统计预测类别不同的数据在5个等分区间内的个数,由于统计的是数组中所有值,所以统计个数是行*列的值\n",
    "proba_his_no = np.histogram(proba_no,bins=5)\n",
    "print('预测类别不同的区间个数统计%s\\n概率统计区间分布%s'% proba_his_no)\n",
    "proba_his_ok = np.histogram(proba_ok,bins=5)\n",
    "print('预测类别相同的区间个数统计%s\\n概率统计区间分布%s'% (proba_his_ok))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1821,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 3) 2\n",
      "standardScaler.mean_ [-0.1041486  -0.03981066  0.09162495]\n",
      "standardScaler.var_ [1.20553777 1.35602197 1.0400875 ]\n",
      "x_train.var 1.0000000000000002\n",
      "x_train.std 1.0\n",
      "X_train= [[ 0.90753027 -0.2449489  -0.6391739 ]\n",
      " [-0.1882497  -1.2388795   0.7400003 ]\n",
      " [-0.77783026 -1.45828494  0.93072705]]\n",
      "X_test= [[ 0.09734242 -0.58347168 -0.66190289]\n",
      " [ 1.24237466 -0.84295228  0.33413916]\n",
      " [-0.81125864 -0.312655   -1.44741702]]\n",
      "y_train= [1 1 1]\n",
      "y_test= [1 1 0]\n"
     ]
    }
   ],
   "source": [
    "print(X.shape, X.ndim)\n",
    "print('standardScaler.mean_', standardScaler.mean_)  #均值\n",
    "print('standardScaler.var_', standardScaler.var_)  #方差\n",
    "print('x_train.var', np.var(X_train))  #方差\n",
    "print('x_train.std', np.std(X_train))  #标准差\n",
    "print('X_train=', X_train[:3])\n",
    "print('X_test=', X_test[:3])\n",
    "print('y_train=', y_train[:3])\n",
    "print('y_test=', y_test[:3])\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-50a0962a",
   "language": "python",
   "display_name": "PyCharm (python-demo)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}