{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from matplotlib import cm\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use(plt.style.available[0])  #可以通过下标进行选择适合自己的画图样式\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.datasets import make_classification"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "###### 生成均值为 mu，标准偏差为 sigma, 元素个数 size(row,column), 服从正态分布的二维数组\n",
    "mu, sigma, size = -10, 100, (100, 2)  # mean and standard deviation\n",
    "X = np.random.normal(mu, sigma, size)\n",
    "\n",
    "y = np.array(X[:, 1] - X[:, 0])  # 生成因变量Y\n",
    "y[y > 0] = 1\n",
    "y[y < 0] = -1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "outputs": [],
   "source": [
    "# 两个信息特性，每个类一个集群\n",
    "X, y = make_classification(n_samples=100,n_features=2, n_redundant=0, n_informative=2,\n",
    "                             n_clusters_per_class=1, flip_y=0.5)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X=  [[ 0.99404188 -0.93638321]\n",
      " [ 2.7496529   0.46094669]\n",
      " [ 1.45311037  0.85888639]]\n",
      "y=  [1 1 1 0 0]\n",
      "(1000, 2) 2\n",
      "(1000,) 1\n"
     ]
    }
   ],
   "source": [
    "print('X= ', X[:3])\n",
    "print('y= ', y[:5])\n",
    "print(X.shape, X.ndim)\n",
    "print(y.shape, y.ndim)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "outputs": [],
   "source": [
    "#将数据划分为训练集和验证集\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "###### 混淆测试集目标类别的 指定概率50%的错误\n",
    "err = y_train\n",
    "for i in range(int(len(err) * 0.5)):\n",
    "    index = int(np.random.randint(len(err)))\n",
    "    err[index] = 0 if err[index] == 1 else 1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 470,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "outputs": [],
   "source": [
    "# 查看测试集是否与未混淆后不同\n",
    "# print(np.sum(y_train>0) + np.sum(y_test>0), np.sum(y > 0))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "outputs": [],
   "source": [
    "# 3. 特征工程（标准化）\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "standardScaler = StandardScaler()\n",
    "\n",
    "# 测试集 计算平均值和标准偏差 缩放特征集\n",
    "X_train = standardScaler.fit_transform(X_train)\n",
    "X_test = standardScaler.transform(X_test)\n",
    "# X = standardScaler.fit_transform(X)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "outputs": [],
   "source": [
    "# Fit regression model\n",
    "classifiers = [\n",
    "    SVC(kernel=\"rbf\", C=10, gamma=1),\n",
    "    SVC(kernel=\"linear\", C=10, gamma=\"auto\"),\n",
    "]\n",
    "\n",
    "names = [\n",
    "    \"RBF SVM\",\n",
    "    \"Linear SVM\",\n",
    "]\n",
    "svc_rbf = SVC(kernel=\"rbf\", C=10, gamma=1)\n",
    "svc_lin = SVC(kernel=\"linear\", C=10, gamma=\"auto\")\n",
    "svc_poly = SVC(kernel=\"poly\", C=10, gamma=\"auto\", degree=3, coef0=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ix=0, svcs=SVC(C=10, gamma=1)\n",
      "估计器的参数: {'C': 10, 'break_ties': False, 'cache_size': 200, 'class_weight': None, 'coef0': 0.0, 'decision_function_shape': 'ovr', 'degree': 3, 'gamma': 1, 'kernel': 'rbf', 'max_iter': -1, 'probability': False, 'random_state': None, 'shrinking': True, 'tol': 0.001, 'verbose': False}\n",
      "训练集R2评分: 0.58 \n",
      "测试集R2评分: 0.748 \n",
      "ix=1, svcs=SVC(C=10, gamma='auto', kernel='linear')\n",
      "估计器的参数: {'C': 10, 'break_ties': False, 'cache_size': 200, 'class_weight': None, 'coef0': 0.0, 'decision_function_shape': 'ovr', 'degree': 3, 'gamma': 'auto', 'kernel': 'linear', 'max_iter': -1, 'probability': False, 'random_state': None, 'shrinking': True, 'tol': 0.001, 'verbose': False}\n",
      "训练集R2评分: 0.5653333333333334 \n",
      "测试集R2评分: 0.768 \n"
     ]
    }
   ],
   "source": [
    "svcs = [svc_rbf, svc_lin]\n",
    "kernel_label = [\"rbf\", \"linear\"]\n",
    "for ix, svc in enumerate(svcs):\n",
    "    performance = svc.fit(X_train, y_train.ravel())\n",
    "    # 获取预测值\n",
    "    y_test_pred = performance.predict(X_test)\n",
    "    # 显示估计器\n",
    "    print(f'ix=%s, svcs=%s' %(ix, svcs[ix]))\n",
    "    # 获取这个估计器的参数\n",
    "    print(f'估计器的参数: %s' %(svc.get_params()))\n",
    "    # https://blog.csdn.net/gracejpw/article/details/101546293\n",
    "    # 返回预测的决定系数R^2\n",
    "    # R^2越接近于1，模型的拟合优度越高。\n",
    "    print(f'训练集R2评分: %s ' % (performance.score(X_train, y_train)))\n",
    "    print(f'测试集R2评分: %s ' % (svc.score(X_test, y_test)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "\n",
    "print(X_train.shape,X_test.shape)\n",
    "XX = np.vstack((X_train,X_test))  #垂直拼接数组\n",
    "print(XX.shape)\n",
    "\n",
    "# figure number\n",
    "fignum = 1\n",
    "\n",
    "# fit the model\n",
    "# 参考 https://blog.csdn.net/qq_43043256/article/details/104259061\n",
    "# for name, penalty in ((\"unreg\", 1), (\"reg\", 0.05)):\n",
    "# for name, penalty in ((\"unreg\", 1), ):\n",
    "for name, clf in zip(names, classifiers):\n",
    "\n",
    "    clf.fit(X, y)\n",
    "    # get the separating hyperplane #获取分离超平面\n",
    "    w = clf.coef_[0]  # 获取w\n",
    "\n",
    "    # 根据超平面 yy= -w0/w1*x1-b1/w1\n",
    "    a = -w[0] / w[1]  #斜率\n",
    "    xx = np.linspace(-5, 5)  #公式中的x1\n",
    "    # 我们得到截距b1和w1后，就可以求出所需要的公式\n",
    "    # clf.intercept_[0]  #用来获得截距b1(这里共有两个值，分别为到x和到y的)\n",
    "    yy = a * xx - (clf.intercept_[0]) / w[1]  #超平面\n",
    "\n",
    "    # 绘制通过的分离超平面的平行线\n",
    "    # 支持向量(从超平面方向上的边距)\n",
    "    # 垂直于超平面)。竖直方向上是sqrt(1+a^2)\n",
    "    # 对于线性回归和逻辑回归，其目标函数为：\n",
    "    # g(x) = w1x1 + w2x2 + w3x3 + w4x4 + w0\n",
    "    # coef_和intercept_都是模型参数，即为w\n",
    "    # coef_为w1到w4\n",
    "    # intercept_为w0\n",
    "    # 如果有激活函数sigmoid，增加非线性变化  则为分类  即逻辑回归\n",
    "    # 如果没有激活函数，则为回归\n",
    "    # 对于这样的线性函数，都会有coef_和intercept_函数\n",
    "    margin = 1 / np.sqrt(np.sum(clf.coef_ ** 2))\n",
    "    yy_down = yy - np.sqrt(1 + a ** 2) * margin  #下边界\n",
    "    yy_up = yy + np.sqrt(1 + a ** 2) * margin  #上边界\n",
    "\n",
    "    # plot the line, the points, and the nearest vectors to the plane\n",
    "    # 绘制直线、点和距离平面最近的向量\n",
    "    plt.figure(fignum, figsize=(4, 3))\n",
    "    plt.clf()\n",
    "    plt.plot(xx, yy, \"k-\")\n",
    "    plt.plot(xx, yy_down, \"k--\")\n",
    "    plt.plot(xx, yy_up, \"k--\")\n",
    "\n",
    "    plt.scatter(\n",
    "        clf.support_vectors_[:, 0],  #分类0的支持向量\n",
    "        clf.support_vectors_[:, 1],  #分类1的支持向量\n",
    "        s=80,\n",
    "        facecolors=\"none\",\n",
    "        zorder=10,\n",
    "        edgecolors=\"k\",\n",
    "        cmap=cm.get_cmap(\"RdBu\"),\n",
    "    )\n",
    "    plt.scatter(\n",
    "        X[:, 0], X[:, 1], c=y, zorder=10, cmap=cm.get_cmap(\"RdBu\"), edgecolors=\"k\"\n",
    "    )\n",
    "\n",
    "    plt.axis(\"tight\")\n",
    "    x_min = -4.8\n",
    "    x_max = 4.2\n",
    "    y_min = -6\n",
    "    y_max = 6\n",
    "\n",
    "    YY, XX = np.meshgrid(yy, xx)\n",
    "    xy = np.vstack([XX.ravel(), YY.ravel()]).T\n",
    "    Z = clf.decision_function(xy).reshape(XX.shape)\n",
    "\n",
    "    # Put the result into a contour plot #将结果放入等高线图\n",
    "    plt.contourf(XX, YY, Z, cmap=cm.get_cmap(\"RdBu\"), alpha=0.5, linestyles=[\"-\"])\n",
    "\n",
    "    plt.xlim(x_min, x_max)\n",
    "    plt.ylim(y_min, y_max)\n",
    "\n",
    "    plt.xticks(())\n",
    "    plt.yticks(())\n",
    "    fignum = fignum + 1\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 475,
   "outputs": [
    {
     "data": {
      "text/plain": "'\\n\\nprint(X_train.shape,X_test.shape)\\nXX = np.vstack((X_train,X_test))  #垂直拼接数组\\nprint(XX.shape)\\n\\n# figure number\\nfignum = 1\\n\\n# fit the model\\n# 参考 https://blog.csdn.net/qq_43043256/article/details/104259061\\n# for name, penalty in ((\"unreg\", 1), (\"reg\", 0.05)):\\n# for name, penalty in ((\"unreg\", 1), ):\\nfor name, clf in zip(names, classifiers):\\n\\n    clf.fit(X, y)\\n    # get the separating hyperplane #获取分离超平面\\n    w = clf.coef_[0]  # 获取w\\n\\n    # 根据超平面 yy= -w0/w1*x1-b1/w1\\n    a = -w[0] / w[1]  #斜率\\n    xx = np.linspace(-5, 5)  #公式中的x1\\n    # 我们得到截距b1和w1后，就可以求出所需要的公式\\n    # clf.intercept_[0]  #用来获得截距b1(这里共有两个值，分别为到x和到y的)\\n    yy = a * xx - (clf.intercept_[0]) / w[1]  #超平面\\n\\n    # 绘制通过的分离超平面的平行线\\n    # 支持向量(从超平面方向上的边距)\\n    # 垂直于超平面)。竖直方向上是sqrt(1+a^2)\\n    # 对于线性回归和逻辑回归，其目标函数为：\\n    # g(x) = w1x1 + w2x2 + w3x3 + w4x4 + w0\\n    # coef_和intercept_都是模型参数，即为w\\n    # coef_为w1到w4\\n    # intercept_为w0\\n    # 如果有激活函数sigmoid，增加非线性变化  则为分类  即逻辑回归\\n    # 如果没有激活函数，则为回归\\n    # 对于这样的线性函数，都会有coef_和intercept_函数\\n    margin = 1 / np.sqrt(np.sum(clf.coef_ ** 2))\\n    yy_down = yy - np.sqrt(1 + a ** 2) * margin  #下边界\\n    yy_up = yy + np.sqrt(1 + a ** 2) * margin  #上边界\\n\\n    # plot the line, the points, and the nearest vectors to the plane\\n    # 绘制直线、点和距离平面最近的向量\\n    plt.figure(fignum, figsize=(4, 3))\\n    plt.clf()\\n    plt.plot(xx, yy, \"k-\")\\n    plt.plot(xx, yy_down, \"k--\")\\n    plt.plot(xx, yy_up, \"k--\")\\n\\n    plt.scatter(\\n        clf.support_vectors_[:, 0],  #分类0的支持向量\\n        clf.support_vectors_[:, 1],  #分类1的支持向量\\n        s=80,\\n        facecolors=\"none\",\\n        zorder=10,\\n        edgecolors=\"k\",\\n        cmap=cm.get_cmap(\"RdBu\"),\\n    )\\n    plt.scatter(\\n        X[:, 0], X[:, 1], c=y, zorder=10, cmap=cm.get_cmap(\"RdBu\"), edgecolors=\"k\"\\n    )\\n\\n    plt.axis(\"tight\")\\n    x_min = -4.8\\n    x_max = 4.2\\n    y_min = -6\\n    y_max = 6\\n\\n    YY, XX = np.meshgrid(yy, xx)\\n    xy = np.vstack([XX.ravel(), YY.ravel()]).T\\n    Z = clf.decision_function(xy).reshape(XX.shape)\\n\\n    # Put the result into a contour plot #将结果放入等高线图\\n    plt.contourf(XX, YY, Z, cmap=cm.get_cmap(\"RdBu\"), alpha=0.5, linestyles=[\"-\"])\\n\\n    plt.xlim(x_min, x_max)\\n    plt.ylim(y_min, y_max)\\n\\n    plt.xticks(())\\n    plt.yticks(())\\n    fignum = fignum + 1\\n\\nplt.show()\\n\\n'"
     },
     "execution_count": 475,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(681, 2)\n",
      "(681,)\n",
      "(666,)\n",
      "(681,)\n",
      "(681, 2)\n"
     ]
    }
   ],
   "source": [
    "print(svc.support_vectors_.shape)\n",
    "print(svc.support_.shape)\n",
    "print(svc_rbf.support_.shape)\n",
    "print(svc_lin.support_.shape)\n",
    "print(svc_lin.support_vectors_.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 2) 2\n",
      "standardScaler.mean_ [0.98739369 0.01613228]\n",
      "standardScaler.var_ [0.58086419 1.18980639]\n",
      "x_train.var 0.9999999999999994\n",
      "x_train.std 0.9999999999999997\n",
      "X_train= [[ 0.87428368  0.81309755]\n",
      " [ 0.41700611  0.69510598]\n",
      " [-1.92896813  1.39822587]]\n",
      "X_test= [[-0.15484053 -0.76231759]\n",
      " [ 0.30223092 -1.12665987]\n",
      " [-0.16239218 -0.79864524]]\n",
      "y_train= [0 0 1]\n",
      "y_test= [0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(X.shape,X.ndim)\n",
    "print('standardScaler.mean_', standardScaler.mean_)  #均值\n",
    "print('standardScaler.var_', standardScaler.var_)  #方差\n",
    "print('x_train.var', np.var(X_train))  #方差\n",
    "print('x_train.std', np.std(X_train))  #标准差\n",
    "print('X_train=', X_train[:3])\n",
    "print('X_test=', X_test[:3])\n",
    "print('y_train=', y_train[:3])\n",
    "print('y_test=', y_test[:3])\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-50a0962a",
   "language": "python",
   "display_name": "PyCharm (python-demo)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}